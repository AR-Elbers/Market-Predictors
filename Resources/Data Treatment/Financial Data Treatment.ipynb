{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas to access and manipulate our data\n",
    "import pandas as pd\n",
    "\n",
    "# Establish contact with the csv data files\n",
    "data_1 = \"../Raw Data/XAU_USD 12-1979 to 01-1885.csv\"\n",
    "data_2 = \"../Raw Data/XAU_USD 01-1985 to 01-2000.csv\"\n",
    "data_3 = \"../Raw Data/XAU_USD 01-2000 to 12-2010.csv\"\n",
    "data_4 = \"../Raw Data/XAU_USD 12-2010 to 02-2021.csv\"\n",
    "\n",
    "# Read CSV with pandas\n",
    "read_1 = pd.read_csv(data_1)\n",
    "read_2 = pd.read_csv(data_2)\n",
    "read_3 = pd.read_csv(data_3)\n",
    "read_4 = pd.read_csv(data_4)\n",
    "\n",
    "\n",
    "read_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_3['Price']=read_3.Price.str.replace(',','').astype(float)\n",
    "read_3['Open']=read_3.Open.str.replace(',','').astype(float)\n",
    "read_3['High']=read_3.High.str.replace(',','').astype(float)\n",
    "read_3['Low']=read_3.Low.str.replace(',','').astype(float)\n",
    "\n",
    "read_3.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_4['Price']=read_4.Price.str.replace(',','').astype(float)\n",
    "read_4['Open']=read_4.Open.str.replace(',','').astype(float)\n",
    "read_4['High']=read_4.High.str.replace(',','').astype(float)\n",
    "read_4['Low']=read_4.Low.str.replace(',','').astype(float)\n",
    "\n",
    "read_4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we must merge our data into one table\n",
    "# Because we are merging data accross the same columns we use pd.concat function\n",
    "data_merged = pd.concat([read_1, read_2, read_3, read_4])\n",
    "\n",
    "# Check our data order and number of rows - we reached the 10,000 data point minimum for NLP\n",
    "data_merged.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged['Date'] = pd.to_datetime(data_merged['Date'])\n",
    "\n",
    "gold_df= data_merged.sort_values(by='Date')\n",
    "\n",
    "gold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df['XAU/USD'] = gold_df['Price']\n",
    "\n",
    "gold_df = gold_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Data Frame \n",
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data on the Remaining Assets\n",
    "\n",
    "bonds_10y_raw = \"../Raw Data/10YearBonds.csv\"\n",
    "\n",
    "nasdaq_raw = \"../Raw Data/NASDAQ.csv\"\n",
    "\n",
    "nikkei_raw = \"../Raw Data/Nikkei225.csv\"   \n",
    "\n",
    "# Read CSV's with pandas\n",
    "read_bonds = pd.read_csv(bonds_10y_raw)\n",
    "\n",
    "read_nasdaq = pd.read_csv(nasdaq_raw)\n",
    "\n",
    "read_nikkei = pd.read_csv(nikkei_raw)\n",
    "\n",
    "read_bonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-label the relevant columns of our data\n",
    "\n",
    "bonds_df = pd.DataFrame(read_bonds)\n",
    "nasdaq_df = pd.DataFrame(read_nasdaq)\n",
    "nikkei_df = pd.DataFrame(read_nikkei)\n",
    "\n",
    "\n",
    "# Rename the closing price column\n",
    "\n",
    "bonds_df['Bonds 10year'] = bonds_df['Close']\n",
    "\n",
    "nasdaq_df['NASDAQ 100'] = nasdaq_df['Close']\n",
    "\n",
    "nikkei_df['NIKKEI 225'] = nikkei_df['Close']\n",
    "nikkei_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Date is on the correct format accrosss tables \n",
    "# and create new DF's only with the desired columns\n",
    "\n",
    "bonds_df['Date'] = pd.to_datetime(bonds_df['Date'])\n",
    "bonds_df = bonds_df[['Date','Bonds 10year']]\n",
    "\n",
    "nasdaq_df['Date'] = pd.to_datetime(nasdaq_df['Date'])\n",
    "nasdaq_df = nasdaq_df[['Date','NASDAQ 100']]\n",
    "\n",
    "nikkei_df['Date'] = pd.to_datetime(nikkei_df['Date'])\n",
    "nikkei_df = nikkei_df[['Date','NIKKEI 225']]\n",
    "\n",
    "gold_df = gold_df[['Date','XAU/USD']]\n",
    "\n",
    "#Code to merge the dataframes for future correlation analysis\n",
    "# merge1 = pd.merge(bonds_df, nasdaq_df, how='outer', on='Date')\n",
    "\n",
    "# merge2 = pd.merge(merge1, nikkei_df, how='outer', on='Date')\n",
    "\n",
    "# merge3 = pd.merge(merge2, gold_df, how='outer', on='Date')\n",
    "\n",
    "# merge3\n",
    "gold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns on the 3 data sets\n",
    "\n",
    "nikkei_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a count of dupicates in our data sets\n",
    "print(gold_df.duplicated(subset = 'Date').sum())\n",
    "print(bonds_df.duplicated(subset = 'Date').sum())\n",
    "print(nasdaq_df.duplicated(subset = 'Date').sum())\n",
    "print(nikkei_df.duplicated(subset = 'Date').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null values on all data sets\n",
    "\n",
    "gold = gold_df.dropna()\n",
    "bonds = bonds_df.dropna()\n",
    "nasdaq = nasdaq_df.dropna()\n",
    "nikkei = nikkei_df.dropna()\n",
    "\n",
    "# Set the date value as our index\n",
    "gold.set_index('Date', inplace=True)\n",
    "bonds.set_index('Date', inplace=True)\n",
    "nasdaq.set_index('Date', inplace=True)\n",
    "nikkei.set_index('Date', inplace=True)\n",
    "nikkei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our Value data in separate csv files\n",
    "\n",
    "gold.to_csv('Gold (closing price).csv')\n",
    "bonds.to_csv('Bonds (closing price).csv')\n",
    "nasdaq.to_csv('Nasdaq (closing price).csv')\n",
    "nikkei.to_csv('Nikkei (closing price).csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read CSV with pandas\n",
    "\n",
    "# cols = gold.select_dtypes(exclude=['float']).columns\n",
    "\n",
    "# gold[cols] = gold[cols].apply(pd.to_numeric, downcast='float', errors='raise')\n",
    "\n",
    "# gold.convert_dtypes(infer_objects=True, convert_string=True, convert_integer=True, convert_boolean=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nikkei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily returns for each df in a new df\n",
    "nikkei_return = (nikkei.pct_change()*100)\n",
    "bonds_return = (bonds.pct_change()*100)\n",
    "nasdaq_return = (nasdaq.pct_change()*100)\n",
    "# gold_return = (gold.pct_change()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dropna() to drop the first row which will be a null value\n",
    "# gold_return = gold_return.dropna()\n",
    "bonds_return = bonds_return.dropna()\n",
    "nasdaq_return = nasdaq_return.dropna()\n",
    "nikkei_return = nikkei_return.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nikkei_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format our pandas data into %'s\n",
    "pd.options.display.float_format = '{:.2f}%'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_return.to_csv('Gold (daily returns).csv')\n",
    "bonds_return.to_csv('Bonds (daily returns).csv')\n",
    "nasdaq_return.to_csv('Nasdaq (daily returns).csv')\n",
    "nikkei_return.to_csv('Nikkei (daily returns).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}